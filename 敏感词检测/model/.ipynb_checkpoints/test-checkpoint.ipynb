{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "预测\n",
    "\"\"\"\n",
    "import jieba\n",
    "import numpy as np\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import yaml\n",
    "from keras.models import model_from_yaml\n",
    "np.random.seed(1337)  # For Reproducibility\n",
    "import sys\n",
    "sys.setrecursionlimit(1000000)\n",
    "\n",
    "# define parameters\n",
    "maxlen = 100\n",
    "\n",
    "def create_dictionaries(model=None,\n",
    "                        combined=None):\n",
    "    ''' Function does are number of Jobs:\n",
    "        1- Creates a word to index mapping\n",
    "        2- Creates a word to vector mapping\n",
    "        3- Transforms the Training and Testing Dictionaries\n",
    "\n",
    "    '''\n",
    "    if (combined is not None) and (model is not None):\n",
    "        gensim_dict = Dictionary()\n",
    "        gensim_dict.doc2bow(model.wv.vocab.keys(),\n",
    "                            allow_update=True)\n",
    "        #  freqxiao10->0 所以k+1\n",
    "        w2indx = {v: k+1 for k, v in gensim_dict.items()}#所有频数超过1的词语的索引,(k->v)=>(v->k)\n",
    "        w2vec = {word: model[word] for word in w2indx.keys()}#所有频数超过1的词语的词向量, (word->model(word))\n",
    "\n",
    "        def parse_dataset(combined): # 闭包-->临时使用\n",
    "            ''' Words become integers\n",
    "            '''\n",
    "            data=[]\n",
    "            for sentence in combined:\n",
    "                new_txt = []\n",
    "                for word in sentence:\n",
    "                    try:\n",
    "                        new_txt.append(w2indx[word])\n",
    "                    except:\n",
    "                        new_txt.append(0) # freqxiao10->0\n",
    "                data.append(new_txt)\n",
    "            return data # word=>index\n",
    "        combined=parse_dataset(combined)\n",
    "        combined= sequence.pad_sequences(combined, maxlen=maxlen)#每个句子所含词语对应的索引，所以句子中含有频数小于10的词语，索引为0\n",
    "        return w2indx, w2vec,combined\n",
    "    else:\n",
    "        print ('No data provided...')\n",
    "\n",
    "\n",
    "def input_transform(words,model):\n",
    "    words=np.array(words).reshape(1,-1)\n",
    "    _,_,combined=create_dictionaries(model,words)\n",
    "    return combined\n",
    "\n",
    "\n",
    "def lstm_predict(string,model,Word2vec_model):\n",
    "    conut=0\n",
    "    words=jieba.lcut(string)\n",
    "    for word in words:\n",
    "        data=input_transform(word,Word2vec_model)\n",
    "        data.reshape(1,-1)\n",
    "        #print data\n",
    "        result=model.predict_classes(data)\n",
    "#         print (word,result) #返回的结果    \n",
    "        if result[0]==0:\n",
    "            conut=conut+1\n",
    "    print(\"[\",string,\"]的敏感词数:\",conut)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取文件的模型放出来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:2: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "with open('lstm.yml', 'r') as f:\n",
    "    yaml_string = yaml.load(f)\n",
    "model = model_from_yaml(yaml_string)\n",
    "model.load_weights('lstm.h5')\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "Word2vec_model=Word2Vec.load('Word2vec_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "[ 射精 ]的敏感词数: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "string = \"射精\"\n",
    "lstm_predict(string,model,Word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]]\n",
      "[ 干杯 ]的敏感词数: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "string = \"干杯\"\n",
    "lstm_predict(string,model,Word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]]\n",
      "[ 强奸 ]的敏感词数: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "string = \"强奸\"\n",
    "lstm_predict(string,model,Word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:33: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "厉害 [[1]]\n",
      "的 [[1]]\n",
      "鲍鱼 [[0]]\n",
      "会 [[1]]\n",
      "射精 [[0]]\n",
      ", [[0]]\n",
      "不过 [[1]]\n",
      "他 [[0]]\n",
      "爱 [[0]]\n",
      "强奸 [[0]]\n",
      "[ 厉害的鲍鱼会射精,不过他爱强奸 ]的敏感词数: 6\n"
     ]
    }
   ],
   "source": [
    "string = \"厉害的鲍鱼会射精,不过他爱强奸\"\n",
    "lstm_predict(string,model,Word2vec_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
